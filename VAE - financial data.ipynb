{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\".keys\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(data):\n",
    "\td = np.array([(x[0], x[1]) for x in data]).T\n",
    "\tdates = d[0][::-1]\n",
    "\tprices = d[1][::-1]\n",
    "\tdatadict = {\n",
    "\t\t\t\"dates\": dates.tolist(),\n",
    "\t\t\t\"prices\": prices.tolist()\n",
    "\t\t}\n",
    "\treturn datadict, d.T\n",
    "\n",
    "def api_request(symbol_text, url=None, **kwargs):\n",
    "\tkey = os.environ.get('QUANDL_KEY')\n",
    "\tkey = ''.join(['api_key=', key])\n",
    "\t#TODO change url and get datasettype part separate\n",
    "\tif url is None:\n",
    "\t\turl = os.environ.get('QUANDL_URL')\n",
    "\turl = url+symbol_text+'.json'\n",
    "\turl = url + '?'\n",
    "\tif len(kwargs)>0:\n",
    "\t\tcounter = 0\n",
    "\t\tfor k,v in kwargs.items():\n",
    "\t\t\turl = url + k + '=' + v\n",
    "\t\t\turl=url+'&'\n",
    "\t\t\tcounter+=1\n",
    "\turl = ''.join([url,key])\n",
    "\tprint(url)\n",
    "\tr = requests.get(url).json()\n",
    "\td = r['dataset']['data']\n",
    "\treturn d\n",
    "\n",
    "def get_single_df(symbolname, startdate):\n",
    "    dict_, d = transform(\n",
    "        api_request(symbolname ,\n",
    "                    start_date = startdate, \n",
    "                    )\n",
    "    )\n",
    "    df = pd.DataFrame(d[:,1], index = d[:,0])\n",
    "    df.columns = [symbolname]\n",
    "    return df\n",
    "\n",
    "def get_multi_df(symbol_list, startdate):\n",
    "    df = pd.DataFrame()\n",
    "    for symbol in symbol_list:\n",
    "        ddf = get_single_df(symbol, startdate).astype(float)\n",
    "        df = df.join(ddf , how='outer')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.quandl.com/api/v3/datasets/WIKI/gs.json?start_date=2017-01-01&api_key=o7ncuZZnSjU8JNYUBnxq\n",
      "https://www.quandl.com/api/v3/datasets/WIKI/c.json?start_date=2017-01-01&api_key=o7ncuZZnSjU8JNYUBnxq\n"
     ]
    }
   ],
   "source": [
    "df = get_multi_df(['gs', 'c'],'2017-01-01' )\n",
    "\n",
    "#projected return of buying today\n",
    "df = (df.shift(1)-df)/df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(df[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = (data - data.mean(axis=0)) / data.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_data.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriceData:\n",
    "    def __init__(self, array):\n",
    "        self.array = array\n",
    "        self.datalength = array.shape[0]\n",
    "        \n",
    "        self.pointer = 0\n",
    "    def next_batch(self, n):\n",
    "        if self.pointer + n + 1 >= self.datalength:\n",
    "            self.pointer = np.random.randint(n)\n",
    "        next_batch = self.array[self.pointer : min(self.pointer+n, self.datalength)]\n",
    "        self.pointer += n\n",
    "        return next_batch\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricedata = PriceData(normalized_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xavier_init(size):\n",
    "    in_dim = size[0]\n",
    "    xavier_stddev = 1. / tf.sqrt(in_dim / 2.)\n",
    "    return tf.random_normal(shape=size, stddev=xavier_stddev)\n",
    "# def xavier_init(fan_in, fan_out, constant=1): \n",
    "#     \"\"\" Xavier initialization of network weights\"\"\"\n",
    "#     # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "#     low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "#     high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "#     return tf.random_uniform((fan_in, fan_out), \n",
    "#                              minval=low, maxval=high, \n",
    "#                              dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fully-conected layer\n",
    "def dense(x, inputFeatures, outputFeatures, scope=None, with_w=False):\n",
    "    matrix = tf.Variable(xavier_init([inputFeatures, outputFeatures]))\n",
    "    bias = tf.Variable( tf.zeros(shape = [outputFeatures]))\n",
    "    if with_w:\n",
    "        return tf.matmul(x, matrix) + bias, matrix, bias\n",
    "    else:\n",
    "        return tf.matmul(x, matrix) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_z = 20         # size of code \n",
    "batchsize = 32\n",
    "data_dim = 2\n",
    "h_size = 30\n",
    "\n",
    "# ENCODER\n",
    "X = tf.placeholder(tf.float32, shape=[None, data_dim])\n",
    "def encoder(x):\n",
    "    with tf.variable_scope(\"encoder\"):\n",
    "        E_1 = tf.nn.relu(dense(x, data_dim, h_size))\n",
    "        E_2 = tf.nn.relu(dense(E_1, h_size, h_size))\n",
    "        z_mean = dense(E_2, h_size, n_z)\n",
    "        z_stddev = dense(E_2, h_size, n_z)\n",
    "    return z_mean, z_stddev\n",
    "\n",
    "# DECODER\n",
    "def decoder(z):\n",
    "    with tf.variable_scope(\"decoder\"):\n",
    "        D_1 = tf.nn.relu(dense(z, n_z, h_size))\n",
    "        D_log_prob = dense(D_1, h_size, data_dim)\n",
    "        #D_prob = tf.nn.sigmoid(D_log_prob)\n",
    "    return D_log_prob#D_prob\n",
    "\n",
    "\n",
    "\n",
    "z_mean, z_stddev = encoder(X)\n",
    "\n",
    "\n",
    "samples = tf.random_normal([tf.shape(X)[0], n_z], 0, 1, dtype=tf.float32)\n",
    "z_code = z_mean + (z_stddev * samples)\n",
    "\n",
    "generated_images = decoder(z_code)\n",
    "\n",
    "\n",
    "# LOSS\n",
    "generation_loss = tf.reduce_mean(tf.square(X - generated_images), axis = 1) #MSE\n",
    "# generation_loss = -tf.reduce_sum(X * tf.log(1e-8 + generated_images) \n",
    "#                                  + \n",
    "#                                  (1-X) * tf.log(1e-7 + 1 - generated_images)\n",
    "#                                  ,1)\n",
    "latent_loss = 0.5 * tf.reduce_sum(tf.square(z_mean) + tf.square(z_stddev) - tf.log(tf.square(z_stddev)) - 1,1)\n",
    "loss = tf.reduce_mean(generation_loss + latent_loss)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(0.0001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0\n",
      "gen_loss: 16.84\n",
      "lat_loss: 54.97\n",
      "\n",
      "Iter: 10000\n",
      "gen_loss: 2.189\n",
      "lat_loss: 5.537\n",
      "\n",
      "Iter: 20000\n",
      "gen_loss: 0.9951\n",
      "lat_loss: 2.248\n",
      "\n",
      "Iter: 30000\n",
      "gen_loss: 0.5142\n",
      "lat_loss: 2.024\n",
      "\n",
      "Iter: 40000\n",
      "gen_loss: 0.8222\n",
      "lat_loss: 2.078\n",
      "\n",
      "Iter: 50000\n",
      "gen_loss: 0.4995\n",
      "lat_loss: 1.99\n",
      "\n",
      "Iter: 60000\n",
      "gen_loss: 0.4152\n",
      "lat_loss: 1.364\n",
      "\n",
      "Iter: 70000\n",
      "gen_loss: 0.5995\n",
      "lat_loss: 1.083\n",
      "\n",
      "Iter: 80000\n",
      "gen_loss: 0.6205\n",
      "lat_loss: 1.194\n",
      "\n"
     ]
    }
   ],
   "source": [
    "mb_size = batchsize\n",
    "for it in range(90000):\n",
    "    X_mb = pricedata.next_batch(mb_size)\n",
    "\n",
    "    _, gen_loss, lat_loss = sess.run((optimizer, generation_loss, latent_loss), \n",
    "                                     feed_dict={X: X_mb})\n",
    "    if it % 10000 == 0:\n",
    "        print('Iter: {}'.format(it))\n",
    "        print('gen_loss: {:.4}'. format(np.mean(gen_loss)))\n",
    "        print('lat_loss: {:.4}'.format(np.mean(lat_loss)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_distance(df):\n",
    "    return np.mean(np.sum((df-df.shift(1))**2, axis=1)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.354402542114258\n",
      "6.286406517028809\n"
     ]
    }
   ],
   "source": [
    "means = sess.run(z_code, feed_dict={X: pricedata.array})\n",
    "m = pd.DataFrame(means)\n",
    "print(vector_distance(m))\n",
    "n = m.sample(m.shape[0])\n",
    "print(vector_distance(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6892883777618408\n",
      "0.6816578507423401\n"
     ]
    }
   ],
   "source": [
    "means = sess.run(z_mean, feed_dict={X: pricedata.array})\n",
    "m = pd.DataFrame(means)\n",
    "print(vector_distance(m))\n",
    "n = m.sample(m.shape[0])\n",
    "print(vector_distance(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.251519390191801\n"
     ]
    }
   ],
   "source": [
    "f = pd.DataFrame(np.random.normal(0,1,[9999,20]))\n",
    "print(vector_distance(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.normal(0,1,[308,20]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6314297914505005"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = m.sample(m.shape[0])\n",
    "np.mean(np.sum((n-n.shift(1))**2, axis=1)**.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156    0.000000\n",
       "111    0.992212\n",
       "97     1.406284\n",
       "143    1.472060\n",
       "197    1.729580\n",
       "142    1.727712\n",
       "258    2.303002\n",
       "75     0.412611\n",
       "257    1.766589\n",
       "49     2.017220\n",
       "100    2.996723\n",
       "201    2.161570\n",
       "263    2.278406\n",
       "24     0.035527\n",
       "191    0.254428\n",
       "86     1.929938\n",
       "55     1.217537\n",
       "160    1.730768\n",
       "193    1.370728\n",
       "261    1.614218\n",
       "158    2.140208\n",
       "64     2.137058\n",
       "114    0.061556\n",
       "116    3.170644\n",
       "184    3.122384\n",
       "251    0.339305\n",
       "246    0.468829\n",
       "293    3.739318\n",
       "6      2.559864\n",
       "262    0.672618\n",
       "         ...   \n",
       "15     3.849693\n",
       "22     3.744702\n",
       "39     1.626676\n",
       "157    1.689088\n",
       "289    0.270396\n",
       "278    2.912472\n",
       "281    0.084510\n",
       "61     2.727432\n",
       "130    1.555405\n",
       "93     1.710295\n",
       "235    1.756573\n",
       "18     1.472773\n",
       "155    0.137773\n",
       "227    0.603282\n",
       "74     0.942208\n",
       "241    1.681362\n",
       "83     1.522941\n",
       "76     0.473064\n",
       "73     2.976344\n",
       "69     2.893823\n",
       "276    0.197499\n",
       "292    2.169687\n",
       "70     1.663108\n",
       "30     4.130243\n",
       "126    1.777059\n",
       "80     3.340203\n",
       "214    4.433860\n",
       "45     2.580897\n",
       "199    2.105612\n",
       "129    1.750712\n",
       "Length: 308, dtype: float32"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((n-n.shift(1))**2, axis=1)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
